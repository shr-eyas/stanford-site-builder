# Research

Our mission is to develop theoretical foundations and practical algorithms for interactive robot learning. Our group is focused on formalizing interactions and how to learn from diverse sources of data to build sample-efficient, human-aligned, and interactive robot policies. We leverage tools from machine learning, control theory, and cognitive science for building robots that can seamlessly coordinate with, collaborate with, compete with, or influence humans.

## Areas

### Foundation Models for Robotics
image: https://placehold.co/400x300/e8e8e8/666?text=Research+GIF+1

Large language models and vision-language models offer new opportunities for robot learning. We investigate how to leverage these foundation models for task specification, planning, and skill learning.

### Interactive Robot Learning
image: https://placehold.co/400x300/e8e8e8/666?text=Research+GIF+2

We develop algorithms that enable robots to learn complex manipulation skills from demonstrations, simulations, and real-world interactions. Our approaches combine imitation learning, reinforcement learning, and foundation models.

### Human-AI/Robot Interaction
image: https://placehold.co/400x300/e8e8e8/666?text=Research+GIF+3

Robots must work alongside and assist humans effectively. Our research addresses shared autonomy, intent prediction, and natural communication interfaces between humans and robots.
